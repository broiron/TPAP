{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc829af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49196087",
   "metadata": {},
   "source": [
    "### 'ClassificationCode_invoicee', 'ClassificationCode_invoicer', '품명', '상대계정', 'new', '상대계정_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39921b2",
   "metadata": {},
   "source": [
    "### new = ClassificationCode_invoicee + invoicer + 품명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e71ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./0530학습용_종목품명.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f38be08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23519"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c8efa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassificationCode_invoicee</th>\n",
       "      <th>ClassificationCode_invoicer</th>\n",
       "      <th>품명</th>\n",
       "      <th>상대계정</th>\n",
       "      <th>new</th>\n",
       "      <th>상대계정_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>도시가스제조및공급업</td>\n",
       "      <td>도시가스 요금</td>\n",
       "      <td>수도광열비</td>\n",
       "      <td>소프트웨어자문개발공급업_도시가스제조및공급업_도시가스 요금</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>전신전화 부가통신 임대</td>\n",
       "      <td>기가 인터넷 최대 1G (z!22572238130)</td>\n",
       "      <td>통신비</td>\n",
       "      <td>소프트웨어자문개발공급업_전신전화 부가통신 임대_기가 인터넷 최대 1G (z!2257...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>조명기구</td>\n",
       "      <td>조명기구</td>\n",
       "      <td>소모품비</td>\n",
       "      <td>소프트웨어자문개발공급업_조명기구_조명기구</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>전신전화 부가통신 임대</td>\n",
       "      <td>일반전화 (000204583123)</td>\n",
       "      <td>통신비</td>\n",
       "      <td>소프트웨어자문개발공급업_전신전화 부가통신 임대_일반전화 (000204583123)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>부가통신</td>\n",
       "      <td>12월 원스토어㈜ 상품 판매 서비스이용료</td>\n",
       "      <td>지급수수료</td>\n",
       "      <td>소프트웨어자문개발공급업_부가통신_12월 원스토어㈜ 상품 판매 서비스이용료</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ClassificationCode_invoicee ClassificationCode_invoicer  \\\n",
       "0                소프트웨어자문개발공급업                  도시가스제조및공급업   \n",
       "1                소프트웨어자문개발공급업                전신전화 부가통신 임대   \n",
       "2                소프트웨어자문개발공급업                        조명기구   \n",
       "3                소프트웨어자문개발공급업                전신전화 부가통신 임대   \n",
       "4                소프트웨어자문개발공급업                        부가통신   \n",
       "\n",
       "                             품명   상대계정  \\\n",
       "0                       도시가스 요금  수도광열비   \n",
       "1  기가 인터넷 최대 1G (z!22572238130)    통신비   \n",
       "2                          조명기구   소모품비   \n",
       "3           일반전화 (000204583123)    통신비   \n",
       "4        12월 원스토어㈜ 상품 판매 서비스이용료  지급수수료   \n",
       "\n",
       "                                                 new  상대계정_new  \n",
       "0                    소프트웨어자문개발공급업_도시가스제조및공급업_도시가스 요금         0  \n",
       "1  소프트웨어자문개발공급업_전신전화 부가통신 임대_기가 인터넷 최대 1G (z!2257...         1  \n",
       "2                             소프트웨어자문개발공급업_조명기구_조명기구         2  \n",
       "3      소프트웨어자문개발공급업_전신전화 부가통신 임대_일반전화 (000204583123)         1  \n",
       "4           소프트웨어자문개발공급업_부가통신_12월 원스토어㈜ 상품 판매 서비스이용료         3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd8bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_account = {}\n",
    "num_account_inverse = {}\n",
    "for i, class_ in enumerate(df1['상대계정'].unique()):\n",
    "    num_account[i] = class_\n",
    "    num_account_inverse[class_] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7744ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_account) # 44개의 classification class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a7daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac152e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassificationCode_invoicee</th>\n",
       "      <th>ClassificationCode_invoicer</th>\n",
       "      <th>품명</th>\n",
       "      <th>상대계정</th>\n",
       "      <th>new</th>\n",
       "      <th>상대계정_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>도시가스제조및공급업</td>\n",
       "      <td>도시가스 요금</td>\n",
       "      <td>수도광열비</td>\n",
       "      <td>소프트웨어자문개발공급업_도시가스제조및공급업_도시가스 요금</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>전신전화 부가통신 임대</td>\n",
       "      <td>기가 인터넷 최대 1G (z!22572238130)</td>\n",
       "      <td>통신비</td>\n",
       "      <td>소프트웨어자문개발공급업_전신전화 부가통신 임대_기가 인터넷 최대 1G (z!2257...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>조명기구</td>\n",
       "      <td>조명기구</td>\n",
       "      <td>소모품비</td>\n",
       "      <td>소프트웨어자문개발공급업_조명기구_조명기구</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>전신전화 부가통신 임대</td>\n",
       "      <td>일반전화 (000204583123)</td>\n",
       "      <td>통신비</td>\n",
       "      <td>소프트웨어자문개발공급업_전신전화 부가통신 임대_일반전화 (000204583123)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>소프트웨어자문개발공급업</td>\n",
       "      <td>부가통신</td>\n",
       "      <td>12월 원스토어㈜ 상품 판매 서비스이용료</td>\n",
       "      <td>지급수수료</td>\n",
       "      <td>소프트웨어자문개발공급업_부가통신_12월 원스토어㈜ 상품 판매 서비스이용료</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ClassificationCode_invoicee ClassificationCode_invoicer  \\\n",
       "0                소프트웨어자문개발공급업                  도시가스제조및공급업   \n",
       "1                소프트웨어자문개발공급업                전신전화 부가통신 임대   \n",
       "2                소프트웨어자문개발공급업                        조명기구   \n",
       "3                소프트웨어자문개발공급업                전신전화 부가통신 임대   \n",
       "4                소프트웨어자문개발공급업                        부가통신   \n",
       "\n",
       "                             품명   상대계정  \\\n",
       "0                       도시가스 요금  수도광열비   \n",
       "1  기가 인터넷 최대 1G (z!22572238130)    통신비   \n",
       "2                          조명기구   소모품비   \n",
       "3           일반전화 (000204583123)    통신비   \n",
       "4        12월 원스토어㈜ 상품 판매 서비스이용료  지급수수료   \n",
       "\n",
       "                                                 new  상대계정_new  \n",
       "0                    소프트웨어자문개발공급업_도시가스제조및공급업_도시가스 요금         0  \n",
       "1  소프트웨어자문개발공급업_전신전화 부가통신 임대_기가 인터넷 최대 1G (z!2257...         1  \n",
       "2                             소프트웨어자문개발공급업_조명기구_조명기구         2  \n",
       "3      소프트웨어자문개발공급업_전신전화 부가통신 임대_일반전화 (000204583123)         1  \n",
       "4           소프트웨어자문개발공급업_부가통신_12월 원스토어㈜ 상품 판매 서비스이용료         3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b20cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소프트웨어자문개발공급업_도시가스제조및공급업_도시가스 요금\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df1.iloc[0, 4]) # text (input)\n",
    "print(df1.iloc[0, 5]) # label (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423373f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.df.iloc[idx, 4])\n",
    "        label = self.df.iloc[idx, 5]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a96c0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(df1)\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5c13003",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_dataset:    \n",
    "    np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e896c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca490d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30bda5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(df1)\n",
    "dataset_test = CustomDataset(df1)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=8, sampler = train_sampler, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=8, sampler = val_sampler, num_workers=1)\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,shuffle = True)\n",
    "# validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,shuffle = False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2efcc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c981bf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=44)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada1b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./bert_classcode_44_220531_5e6_e5.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371bf30c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r320/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/r320/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Iteration 100 -> Train Loss: 3.1425, Accuracy: 0.210\n",
      "[Epoch 1/5] Iteration 200 -> Train Loss: 2.8328, Accuracy: 0.263\n",
      "[Epoch 1/5] Iteration 300 -> Train Loss: 2.5299, Accuracy: 0.421\n",
      "[Epoch 1/5] Iteration 400 -> Train Loss: 2.2961, Accuracy: 0.500\n",
      "[Epoch 1/5] Iteration 500 -> Train Loss: 2.1271, Accuracy: 0.509\n",
      "[Epoch 1/5] Iteration 600 -> Train Loss: 2.0125, Accuracy: 0.544\n",
      "[Epoch 1/5] Iteration 700 -> Train Loss: 1.8678, Accuracy: 0.562\n",
      "[Epoch 1/5] Iteration 800 -> Train Loss: 1.8330, Accuracy: 0.559\n",
      "[Epoch 1/5] Iteration 900 -> Train Loss: 1.7246, Accuracy: 0.581\n",
      "[Epoch 1/5] Iteration 1000 -> Train Loss: 1.7678, Accuracy: 0.581\n",
      "[Epoch 1/5] Iteration 1100 -> Train Loss: 1.6670, Accuracy: 0.611\n",
      "[Epoch 1/5] Iteration 1200 -> Train Loss: 1.5621, Accuracy: 0.636\n",
      "[Epoch 1/5] Iteration 1300 -> Train Loss: 1.3755, Accuracy: 0.682\n",
      "[Epoch 1/5] Iteration 1400 -> Train Loss: 1.3356, Accuracy: 0.690\n",
      "[Epoch 1/5] Iteration 1500 -> Train Loss: 1.3220, Accuracy: 0.699\n",
      "[Epoch 1/5] Iteration 1600 -> Train Loss: 1.2922, Accuracy: 0.710\n",
      "[Epoch 1/5] Iteration 1700 -> Train Loss: 1.2195, Accuracy: 0.734\n",
      "[Epoch 1/5] Iteration 1800 -> Train Loss: 1.1619, Accuracy: 0.751\n",
      "[Epoch 1/5] Iteration 1900 -> Train Loss: 1.0743, Accuracy: 0.765\n",
      "[Epoch 1/5] Iteration 2000 -> Train Loss: 1.1247, Accuracy: 0.748\n",
      "[Epoch 1/5] Iteration 2100 -> Train Loss: 1.0829, Accuracy: 0.755\n",
      "[Epoch 1/5] Iteration 2200 -> Train Loss: 1.0356, Accuracy: 0.766\n",
      "[Epoch 1/5] Iteration 2300 -> Train Loss: 0.9394, Accuracy: 0.794\n",
      "[Epoch 2/5] Iteration 2400 -> Train Loss: 1.0402, Accuracy: 0.769\n",
      "[Epoch 2/5] Iteration 2500 -> Train Loss: 0.9530, Accuracy: 0.784\n",
      "[Epoch 2/5] Iteration 2600 -> Train Loss: 0.8358, Accuracy: 0.815\n",
      "[Epoch 2/5] Iteration 2700 -> Train Loss: 0.7713, Accuracy: 0.830\n",
      "[Epoch 2/5] Iteration 2800 -> Train Loss: 0.8792, Accuracy: 0.804\n",
      "[Epoch 2/5] Iteration 2900 -> Train Loss: 0.8146, Accuracy: 0.821\n",
      "[Epoch 2/5] Iteration 3000 -> Train Loss: 0.8015, Accuracy: 0.816\n",
      "[Epoch 2/5] Iteration 3100 -> Train Loss: 0.6850, Accuracy: 0.841\n",
      "[Epoch 2/5] Iteration 3200 -> Train Loss: 0.6715, Accuracy: 0.840\n",
      "[Epoch 2/5] Iteration 3300 -> Train Loss: 0.8312, Accuracy: 0.810\n",
      "[Epoch 2/5] Iteration 3400 -> Train Loss: 0.6753, Accuracy: 0.844\n",
      "[Epoch 2/5] Iteration 3500 -> Train Loss: 0.7910, Accuracy: 0.821\n",
      "[Epoch 2/5] Iteration 3600 -> Train Loss: 0.6231, Accuracy: 0.849\n",
      "[Epoch 2/5] Iteration 3700 -> Train Loss: 0.6486, Accuracy: 0.851\n",
      "[Epoch 2/5] Iteration 3800 -> Train Loss: 0.6936, Accuracy: 0.851\n",
      "[Epoch 2/5] Iteration 3900 -> Train Loss: 0.6720, Accuracy: 0.836\n",
      "[Epoch 2/5] Iteration 4000 -> Train Loss: 0.6834, Accuracy: 0.846\n",
      "[Epoch 2/5] Iteration 4100 -> Train Loss: 0.6554, Accuracy: 0.851\n",
      "[Epoch 2/5] Iteration 4200 -> Train Loss: 0.6311, Accuracy: 0.855\n",
      "[Epoch 2/5] Iteration 4300 -> Train Loss: 0.5979, Accuracy: 0.866\n",
      "[Epoch 2/5] Iteration 4400 -> Train Loss: 0.6116, Accuracy: 0.859\n",
      "[Epoch 2/5] Iteration 4500 -> Train Loss: 0.5466, Accuracy: 0.881\n",
      "[Epoch 2/5] Iteration 4600 -> Train Loss: 0.5810, Accuracy: 0.874\n",
      "[Epoch 2/5] Iteration 4700 -> Train Loss: 0.5446, Accuracy: 0.877\n",
      "[Epoch 3/5] Iteration 4800 -> Train Loss: 0.4949, Accuracy: 0.890\n",
      "[Epoch 3/5] Iteration 4900 -> Train Loss: 0.4730, Accuracy: 0.886\n",
      "[Epoch 3/5] Iteration 5000 -> Train Loss: 0.5311, Accuracy: 0.877\n",
      "[Epoch 3/5] Iteration 5100 -> Train Loss: 0.4928, Accuracy: 0.900\n",
      "[Epoch 3/5] Iteration 5200 -> Train Loss: 0.5207, Accuracy: 0.882\n",
      "[Epoch 3/5] Iteration 5300 -> Train Loss: 0.4800, Accuracy: 0.886\n",
      "[Epoch 3/5] Iteration 5400 -> Train Loss: 0.4504, Accuracy: 0.905\n",
      "[Epoch 3/5] Iteration 5500 -> Train Loss: 0.5072, Accuracy: 0.889\n",
      "[Epoch 3/5] Iteration 5600 -> Train Loss: 0.4612, Accuracy: 0.880\n",
      "[Epoch 3/5] Iteration 5700 -> Train Loss: 0.4670, Accuracy: 0.891\n",
      "[Epoch 3/5] Iteration 5800 -> Train Loss: 0.4288, Accuracy: 0.907\n",
      "[Epoch 3/5] Iteration 5900 -> Train Loss: 0.4058, Accuracy: 0.909\n",
      "[Epoch 3/5] Iteration 6000 -> Train Loss: 0.4479, Accuracy: 0.900\n",
      "[Epoch 3/5] Iteration 6100 -> Train Loss: 0.4531, Accuracy: 0.904\n",
      "[Epoch 3/5] Iteration 6200 -> Train Loss: 0.4586, Accuracy: 0.894\n",
      "[Epoch 3/5] Iteration 6300 -> Train Loss: 0.4184, Accuracy: 0.911\n",
      "[Epoch 3/5] Iteration 6400 -> Train Loss: 0.3786, Accuracy: 0.916\n",
      "[Epoch 3/5] Iteration 6500 -> Train Loss: 0.4023, Accuracy: 0.900\n",
      "[Epoch 3/5] Iteration 6600 -> Train Loss: 0.4537, Accuracy: 0.899\n",
      "[Epoch 3/5] Iteration 6700 -> Train Loss: 0.4121, Accuracy: 0.906\n",
      "[Epoch 3/5] Iteration 6800 -> Train Loss: 0.4061, Accuracy: 0.899\n",
      "[Epoch 3/5] Iteration 6900 -> Train Loss: 0.4249, Accuracy: 0.911\n",
      "[Epoch 3/5] Iteration 7000 -> Train Loss: 0.3640, Accuracy: 0.917\n",
      "[Epoch 4/5] Iteration 7100 -> Train Loss: 0.3874, Accuracy: 0.919\n",
      "[Epoch 4/5] Iteration 7200 -> Train Loss: 0.2967, Accuracy: 0.936\n",
      "[Epoch 4/5] Iteration 7300 -> Train Loss: 0.3254, Accuracy: 0.925\n",
      "[Epoch 4/5] Iteration 7400 -> Train Loss: 0.3857, Accuracy: 0.917\n",
      "[Epoch 4/5] Iteration 7500 -> Train Loss: 0.4511, Accuracy: 0.887\n",
      "[Epoch 4/5] Iteration 7600 -> Train Loss: 0.3207, Accuracy: 0.930\n",
      "[Epoch 4/5] Iteration 7700 -> Train Loss: 0.3368, Accuracy: 0.922\n",
      "[Epoch 4/5] Iteration 7800 -> Train Loss: 0.3546, Accuracy: 0.922\n",
      "[Epoch 4/5] Iteration 7900 -> Train Loss: 0.3078, Accuracy: 0.931\n",
      "[Epoch 4/5] Iteration 8000 -> Train Loss: 0.2865, Accuracy: 0.939\n",
      "[Epoch 4/5] Iteration 8100 -> Train Loss: 0.3776, Accuracy: 0.909\n",
      "[Epoch 4/5] Iteration 8200 -> Train Loss: 0.3033, Accuracy: 0.924\n",
      "[Epoch 4/5] Iteration 8300 -> Train Loss: 0.3138, Accuracy: 0.925\n",
      "[Epoch 4/5] Iteration 8400 -> Train Loss: 0.3404, Accuracy: 0.921\n",
      "[Epoch 4/5] Iteration 8500 -> Train Loss: 0.3485, Accuracy: 0.916\n",
      "[Epoch 4/5] Iteration 8600 -> Train Loss: 0.3601, Accuracy: 0.919\n",
      "[Epoch 4/5] Iteration 8700 -> Train Loss: 0.3314, Accuracy: 0.914\n",
      "[Epoch 4/5] Iteration 8800 -> Train Loss: 0.3109, Accuracy: 0.921\n",
      "[Epoch 4/5] Iteration 8900 -> Train Loss: 0.3046, Accuracy: 0.926\n",
      "[Epoch 4/5] Iteration 9000 -> Train Loss: 0.2903, Accuracy: 0.930\n",
      "[Epoch 4/5] Iteration 9100 -> Train Loss: 0.2984, Accuracy: 0.924\n",
      "[Epoch 4/5] Iteration 9200 -> Train Loss: 0.2794, Accuracy: 0.943\n",
      "[Epoch 4/5] Iteration 9300 -> Train Loss: 0.3124, Accuracy: 0.926\n",
      "[Epoch 4/5] Iteration 9400 -> Train Loss: 0.3904, Accuracy: 0.902\n",
      "[Epoch 5/5] Iteration 9500 -> Train Loss: 0.2781, Accuracy: 0.935\n",
      "[Epoch 5/5] Iteration 9600 -> Train Loss: 0.3059, Accuracy: 0.926\n",
      "[Epoch 5/5] Iteration 9700 -> Train Loss: 0.2670, Accuracy: 0.941\n",
      "[Epoch 5/5] Iteration 9800 -> Train Loss: 0.2558, Accuracy: 0.944\n",
      "[Epoch 5/5] Iteration 9900 -> Train Loss: 0.3552, Accuracy: 0.916\n",
      "[Epoch 5/5] Iteration 10000 -> Train Loss: 0.3081, Accuracy: 0.927\n",
      "[Epoch 5/5] Iteration 10100 -> Train Loss: 0.2602, Accuracy: 0.939\n",
      "[Epoch 5/5] Iteration 10200 -> Train Loss: 0.3092, Accuracy: 0.920\n",
      "[Epoch 5/5] Iteration 10300 -> Train Loss: 0.2012, Accuracy: 0.953\n",
      "[Epoch 5/5] Iteration 10400 -> Train Loss: 0.3658, Accuracy: 0.916\n",
      "[Epoch 5/5] Iteration 10500 -> Train Loss: 0.2218, Accuracy: 0.950\n",
      "[Epoch 5/5] Iteration 10600 -> Train Loss: 0.2874, Accuracy: 0.929\n",
      "[Epoch 5/5] Iteration 10700 -> Train Loss: 0.3202, Accuracy: 0.922\n",
      "[Epoch 5/5] Iteration 10800 -> Train Loss: 0.2583, Accuracy: 0.934\n",
      "[Epoch 5/5] Iteration 10900 -> Train Loss: 0.2368, Accuracy: 0.940\n",
      "[Epoch 5/5] Iteration 11000 -> Train Loss: 0.2843, Accuracy: 0.929\n",
      "[Epoch 5/5] Iteration 11100 -> Train Loss: 0.2532, Accuracy: 0.940\n",
      "[Epoch 5/5] Iteration 11200 -> Train Loss: 0.2716, Accuracy: 0.921\n",
      "[Epoch 5/5] Iteration 11300 -> Train Loss: 0.3406, Accuracy: 0.919\n",
      "[Epoch 5/5] Iteration 11400 -> Train Loss: 0.1982, Accuracy: 0.958\n",
      "[Epoch 5/5] Iteration 11500 -> Train Loss: 0.2497, Accuracy: 0.940\n",
      "[Epoch 5/5] Iteration 11600 -> Train Loss: 0.2473, Accuracy: 0.929\n",
      "[Epoch 5/5] Iteration 11700 -> Train Loss: 0.3022, Accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=5e-6) # 1e-6\n",
    "\n",
    "itr = 1\n",
    "p_itr = 100\n",
    "epochs = 5\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "        \n",
    "        itr+=1\n",
    "    \n",
    "    #model.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bfa80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r320/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/r320/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9287688709334467\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# eval_dataset = CustomDataset(test_df)\n",
    "# eval_loader = DataLoader(eval_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in val_loader:\n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample, label = sample.to(device), label.to(device)\n",
    "    labels = torch.tensor(label)\n",
    "    outputs = model(sample, labels=labels)\n",
    "    _, logits = outputs\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(labels)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(labels)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
